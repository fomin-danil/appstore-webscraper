import streamlit as st
import requests
import csv
import time
import datetime
import pandas as pd

# ----------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# ----------------------------
st.title("Google Play Reviews Scraper")
st.write("–°–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤ –ø–æ ID –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–∑ Google Play –±–µ–∑ API")

app_id = st.text_input("–í–≤–µ–¥–∏—Ç–µ applicationId (–Ω–∞–ø—Ä–∏–º–µ—Ä: com.whatsapp):")
country = st.text_input("–°—Ç—Ä–∞–Ω–∞ (–∫–æ–¥, –Ω–∞–ø—Ä–∏–º–µ—Ä ru, us, de):", "ru")
max_pages = st.number_input("–ú–∞–∫—Å. —Å—Ç—Ä–∞–Ω–∏—Ü", min_value=1, max_value=100, value=10)
delay = st.number_input("–ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)", min_value=0.5, max_value=10.0, value=3.0)

start_btn = st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤")

progress = st.empty()
log_area = st.empty()

def fetch_reviews(app_id, country, max_pages, delay):
    collected = []
    base_url = "https://play.google.com/store/getreviews"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0 Safari/537.36"
    }

    for page in range(max_pages):
        progress.progress((page + 1) / max_pages)

        data = {
            "reviewType": 0,
            "pageNum": page,
            "id": app_id,
            "reviewSortOrder": 0,
            "xhr": 1,
            "hl": country
        }

        resp = requests.post(base_url, data=data, headers=headers)

        # –ë–ª–æ–∫ / CAPTCHA ‚Üí –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
        if resp.status_code != 200 or "<HTML>" in resp.text.upper():
            log_area.error("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω –±–ª–æ–∫ –∏–ª–∏ CAPTCHA, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
            break

        try:
            # –û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç JSON –≤ —Å—Ç—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ ‚Üí –≤—ã—Ä–µ–∑–∞–µ–º
            json_text = resp.text.split("\n")[-1]
            reviews = eval(json_text)[0][2]
        except:
            log_area.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON ‚Üí –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
            break

        if not reviews:
            log_area.info("‚úÖ –û—Ç–∑—ã–≤–æ–≤ –±–æ–ª—å—à–µ –Ω–µ—Ç, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
            break

        for item in reviews:
            collected.append({
                "user": item[1],
                "rating": item[2],
                "date": item[5],
                "comment": item[4],
                "app_id": app_id,
                "country": country
            })

        log_area.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page+1}: –ø–æ–ª—É—á–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤")

        time.sleep(delay)

    return collected


if start_btn:
    if not app_id:
        st.error("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ!")
    else:
        log_area.info("‚è≥ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä...")
        reviews = fetch_reviews(app_id, country, max_pages, delay)

        if reviews:
            df = pd.DataFrame(reviews)
            csv = df.to_csv(index=False).encode("utf-8")
            st.success(f"üéâ –°–±–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω! –í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤: {len(df)}")

            st.download_button(
                "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV",
                csv,
                f"{app_id}_reviews.csv",
                "text/csv"
            )

            st.dataframe(df.head(20))
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –æ—Ç–∑—ã–≤—ã")
